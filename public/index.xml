<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R &amp; Census</title>
    <link>/</link>
    <description>Recent content on R &amp; Census</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Feb 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Map prisons in the United States</title>
      <link>/2018/02/05/map-prisons-in-the-united-states/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/05/map-prisons-in-the-united-states/</guid>
      <description>&lt;p&gt;According to Census 2010, a total number of 2,263,602 persons were incarcerated in the United States. Among them, 172,020 were in federal prisons, 1,248,167 in state prisons, and 682,043 in local jails. Despite 1 in every 110 adults are behind bars, most ordenary people have no idea where are they locked up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(totalcensus)
library(tidyverse)
library(ggmap)

# federal and state prison location and population =============================
# search tables for fedral prison
search_tablecontents(&amp;quot;decennial&amp;quot;)
    # PCT0200005 has the total population in federal prison
    # PCT0200006 has state prison population

# read prison population data
pris_pop &amp;lt;- read_decennial(
    year = 2010,
    states = &amp;quot;US&amp;quot;,
    table_contents = c(
        &amp;quot;total = PCT0200003&amp;quot;, 
        &amp;quot;fed_pris = PCT0200005&amp;quot;, 
        &amp;quot;state_pris = PCT0200006&amp;quot;,
        &amp;quot;local_jail = PCT0200007&amp;quot;
    ),
    summary_level = &amp;quot;county subdivision&amp;quot;,
    show_progress = FALSE
) %&amp;gt;%
    # remove county subdivisions that has no prison popualation
    filter(total != 0 | fed_pris != 0 | state_pris != 0 | local_jail != 0) %&amp;gt;%
    mutate(fed_pris = ifelse(fed_pris == 0, NA, fed_pris)) %&amp;gt;%
    mutate(state_pris = ifelse(state_pris == 0, NA, state_pris)) %&amp;gt;%
    mutate(local_jail = ifelse(local_jail == 0, NA, local_jail))

# summarize prison population
sum_inmates &amp;lt;- pris_pop %&amp;gt;%
    summarise(total_inmates = sum(total),
              total_fedpris = sum(fed_pris, na.rm = TRUE),
              total_statepris = sum(state_pris, na.rm = TRUE),
              total_localjail = sum(local_jail, na.rm = TRUE))


state_map &amp;lt;- map_data(&amp;quot;state&amp;quot;)
ggplot() +
    #geom_path(data = map_data(&amp;quot;world&amp;quot;), aes(long, lat, group = group), color = &amp;quot;grey&amp;quot;, size=0.5) +
    geom_polygon(data = state_map, aes(long, lat, group = group), 
                 fill = &amp;quot;grey97&amp;quot;, color = &amp;quot;grey&amp;quot;, size=0.3) +
    geom_point(data = pris_pop,
               aes(lon, lat, size = state_pris, color = &amp;quot;blue&amp;quot;),
               alpha = 0.8) +
    geom_point(data = pris_pop,
               aes(lon, lat, size = fed_pris, color = &amp;quot;red&amp;quot;),
               alpha = 0.8) +
    geom_point(data = pris_pop,
               aes(lon, lat, size = local_jail, color = &amp;quot;green&amp;quot;),
               alpha = 0.5) +
    scale_x_continuous(limits = c(-124.69, -67), expand = c(0, 0)) +
    scale_y_continuous(limits = c(25.12, 49.39), expand = c(0, 0)) +
    scale_size_area(max_size = 4, breaks = c(1000, 5000, 10000, 20000)) +
    scale_color_identity(guide = &amp;quot;legend&amp;quot;,
                         breaks = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;green&amp;quot;),
                         labels = c(&amp;quot;federal&amp;quot;, &amp;quot;state&amp;quot;, &amp;quot;local&amp;quot;)) +
    guides(color = guide_legend(override.aes = list(alpha = 1, size = 4))) +
    labs(title = &amp;quot;Federal Prisons, State Prisons and Local Jails: Location and Number of Inmates &amp;quot;,
         subtitle = &amp;quot;Spatial resolution: county subdivision&amp;quot;,
         caption = &amp;quot;Source: Census 2010&amp;quot;,
         color = NULL, size = &amp;quot;inmates&amp;quot;) +
    coord_map() +
    theme(
        panel.background = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        legend.position = c(1, 0),
        legend.justification = c(1, 0)
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2018-02-05-map-prisons-in-the-united-states_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is your town named after Lincoln or Washington?</title>
      <link>/2018/01/27/the-most-popular-president-lincoln-or-washington/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/27/the-most-popular-president-lincoln-or-washington/</guid>
      <description>&lt;p&gt;Washington and Lincoln are the two greatest presidents in the history of the United States. This post, however, does not discuss how great they are. Instead, I want to show a fun fact related the two presidents: how many cities and towns (and equivalents) are named after them. I am living in Lincoln, Rhode Island, a town so named in honor of President Lincoln.&lt;/p&gt;
&lt;p&gt;The data are extracted from decennial census 2010, the most detailed census so far. There are 311 cities and towns having “Washington” in their names and 205 having “Lincoln”. We also extract the coordinates and population of these cities and towns and plot them on the US map. There are significantly more places named after “Washington” than “Lincoln” in three states, Indiana , Ohio, and Pennsylvania. They combined have 109 more places with &lt;code&gt;Washington&lt;/code&gt; than with &lt;code&gt;Lincoln&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2018-01-23-the-most-popular-president-lincoln-or-washington_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2018-01-23-the-most-popular-president-lincoln-or-washington_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;816&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here are the code. We use package &lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34;&gt;&lt;code&gt;totalcensus&lt;/code&gt;&lt;/a&gt; to extract data from decennial census 2010.&lt;/p&gt;
&lt;p&gt;Let’s first load packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(totalcensus)
library(data.table)
library(magrittr)
library(ggmap)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define a function to extract census data of cities and towns including particular words in names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_area &amp;lt;- function(keywords){
    # read census data
    selected &amp;lt;- read_decennial(
        year = 2010,
        states = &amp;quot;US&amp;quot;,
        geo_headers = c(&amp;quot;NAME&amp;quot;),
        show_progress = FALSE
    ) %&amp;gt;%
        # select place and county subdivision that have name in NAME
        .[SUMLEV %in% c(&amp;quot;060&amp;quot;, &amp;quot;160&amp;quot;)] %&amp;gt;%
        .[NAME %like% paste0(keywords, collapse = &amp;quot;|&amp;quot;)] %&amp;gt;%
        # remove duplicates by (lon, lat)
        unique(by = c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;))
    
    # add area column to store keywords of area
    for (nm in keywords){
        selected[NAME %like% nm, area := nm]
    }
    
    return(selected)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The cities or town having words “Washington” or “Lincoln” in their names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wl &amp;lt;- get_area(c(&amp;quot;Washington&amp;quot;, &amp;quot;Lincoln&amp;quot;)) %&amp;gt;%
    .[, area := factor(area, c(&amp;quot;Washington&amp;quot;, &amp;quot;Lincoln&amp;quot;))]

# first five rows
  #           lon      lat state                NAME population GEOCOMP SUMLEV       area
  # 1:  -86.10771 33.61350    AL         Lincoln CCD       7771   total    060    Lincoln
  # 2:  -86.07064 33.62218    AL        Lincoln city       6266   total    160    Lincoln
  # 3: -111.27100 34.40035    AZ Washington Park CDP         70   total    160 Washington
  # 4:  -92.13358 33.43522    AR Washington township       1410   total    060 Washington
  # 5:  -92.70242 35.23478    AR Washington township       1852   total    060 Washington&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot the cities and towns on a map.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us &amp;lt;- map_data(&amp;#39;state&amp;#39;)
ggplot(us, aes(long, lat)) +
    geom_map(map=us, aes(map_id=region), fill=&amp;quot;grey97&amp;quot;, color=&amp;quot;grey&amp;quot;) +
    geom_point(data = wl[order(-population)], aes(lon, lat, size = population, color = area), alpha = 0.6) +
    scale_size_area(max_size = 10, breaks = c(1000, 10000, 100000, 500000)) +
    ylim(26, 48.5) +
    annotate(&amp;quot;text&amp;quot;, x = -125, y = 28.5, label = &amp;quot;Washington : 311&amp;quot;, color = &amp;quot;#F8766D&amp;quot;, hjust = 0, alpha = 0.6, size = 8) +
    annotate(&amp;quot;text&amp;quot;, x = -125, y = 26, label = &amp;quot;Lincoln : 205&amp;quot;, color = &amp;quot;#00BFC4&amp;quot;, hjust = 0, alpha = 0.6, size = 8) +
    labs(color = NULL) +
    guides(color = &amp;quot;none&amp;quot;,
           size = guide_legend(override.aes = list(alpha = 0.5))) +
    coord_map() +
    labs(title = &amp;quot;Cities, towns, and equivalents named after Washington and Lincoln&amp;quot;,
         subtitle = &amp;quot;State and counties are NOT included&amp;quot;,
         caption = &amp;quot;Source: decennial census 2010&amp;quot;) +
    theme_bw() +
    theme(legend.position = c(0.9, 0.),
          legend.justification = c(0.5, 0),
          legend.title = element_text(color = &amp;quot;grey40&amp;quot;),
          legend.text = element_text(color = &amp;quot;grey40&amp;quot;),
          panel.grid = element_blank(),
          panel.border = element_blank(),
          axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          plot.caption = element_text(hjust = 0.95, color = &amp;quot;grey30&amp;quot;),
          plot.title = element_text(color = &amp;quot;grey30&amp;quot;),
          plot.subtitle = element_text(color = &amp;quot;grey30&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bar plot of states with most cities or towns named after “Washington” or “Lincoln”,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# count
wl[, .(count = .N), by = .(area, state)] %&amp;gt;%
    .[state %in% c(&amp;quot;IN&amp;quot;, &amp;quot;OH&amp;quot;, &amp;quot;PA&amp;quot;, &amp;quot;MO&amp;quot;, &amp;quot;IA&amp;quot;, &amp;quot;KS&amp;quot;, &amp;quot;NE&amp;quot;, &amp;quot;WI&amp;quot;, &amp;quot;AR&amp;quot;)] %&amp;gt;%
    .[, state := factor(state, levels = c(&amp;quot;IA&amp;quot;, &amp;quot;OH&amp;quot;, &amp;quot;IN&amp;quot;, &amp;quot;KS&amp;quot;, &amp;quot;MO&amp;quot;, &amp;quot;PA&amp;quot;, &amp;quot;NE&amp;quot;, &amp;quot;WI&amp;quot;, &amp;quot;AR&amp;quot;))] %&amp;gt;%
    ggplot(aes(state, count, fill = area)) +
    geom_col(position = &amp;quot;dodge&amp;quot;, alpha = 0.6) +
    labs(title = &amp;#39;States with most cities and towns that have &amp;quot;Washington&amp;quot; or &amp;quot;Lincoln&amp;quot; in the name&amp;#39;,
         fill = NULL) +
    theme(legend.position = c(0.9, 0.85))&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Plot pie charts of racial composition in largest metro areas on a map in R</title>
      <link>/2018/01/17/create-pie-plots-on-a-map-in-r/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/17/create-pie-plots-on-a-map-in-r/</guid>
      <description>&lt;p&gt;Pie chart has been criticized for being a poor visualization and is not recommended in R community. The popular &lt;code&gt;ggplot2&lt;/code&gt; package discourages the use of pie charts and there is no dedicated &lt;code&gt;geom_pie&lt;/code&gt; for it.&lt;/p&gt;
&lt;p&gt;Although the criticism is mostly valid, there is a case that pie chart can be useful: pie charts on maps. Pie charting on map is a compact way to show composition by locations.&lt;/p&gt;
&lt;p&gt;A recent &lt;code&gt;R&lt;/code&gt; package, &lt;a href=&#34;https://github.com/GuangchuangYu/scatterpie&#34;&gt;&lt;code&gt;scatterpie&lt;/code&gt;&lt;/a&gt; by Guangchuang Yu, specializes in making pie charts at multiple locations. This package is an extension of &lt;code&gt;ggplot2&lt;/code&gt; so it will be easy for &lt;code&gt;ggplot2&lt;/code&gt; users.&lt;/p&gt;
&lt;p&gt;We will use &lt;code&gt;scatterpie&lt;/code&gt; package to plot the racial composition of largest metropolitan areas in the United state. The demographics data is extracted from 2016 American Community Survey 1-year estimate with &lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34;&gt;&lt;code&gt;totalcensus&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Let’s first load the required packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(scatterpie)
library(totalcensus)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we extract total population and population of selected races in metro areas from 2016 ACS 1-year estimate. We will only keep metro areas with population over one million.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read all metro data
metro &amp;lt;- read_acs1year(
    year = 2016,
    states = &amp;quot;US&amp;quot;,
    table_contents = c(
        &amp;quot;white = C02003_003&amp;quot;, 
        &amp;quot;black = C02003_004&amp;quot;, 
        &amp;quot;asian = C02003_006&amp;quot;
    ),
    geo_headers = &amp;quot;CBSA&amp;quot;,
    summary_level = &amp;quot;310&amp;quot;
) %&amp;gt;%
    mutate(others = population - white - black - asian)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading US 2016 ACS 1-year survey geography file&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep only largest metro and make some cleaning
largest &amp;lt;- metro %&amp;gt;%
    filter(population &amp;gt; 1e6) %&amp;gt;%
    # Los Angeles metro changed CBSA from 31100 to 31080, hand correct the coordinate
    # mutate(lon = ifelse(GEOID == &amp;quot;31000US31080&amp;quot;, -118.18194, lon),
    #        lat = ifelse(GEOID == &amp;quot;31000US31080&amp;quot;, 34.10939, lat)) %&amp;gt;%
    select(NAME, lon, lat, total = population, white, black, asian, others) %&amp;gt;%
    arrange(-total)

head(largest, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                               NAME       lon      lat
## 1 New York-Newark-Jersey City, NY-NJ-PA Metro Area  -73.8745 40.77432
## 2    Los Angeles-Long Beach-Anaheim, CA Metro Area -118.1819 34.10939
## 3    Chicago-Naperville-Elgin, IL-IN-WI Metro Area  -87.8283 41.82352
##      total    white   black   asian  others
## 1 20153634 11704438 3430610 2215765 2802821
## 2 13310447  7080092  880118 2112197 3238040
## 3  9512968  6202988 1577873  617341 1114766&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the race data, we are ready to make pie plot on a map with package &lt;code&gt;scatterpie&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us &amp;lt;- map_data(&amp;#39;state&amp;#39;)
ggplot(us, aes(long, lat)) +
    geom_map(map=us, aes(map_id=region), fill=&amp;quot;grey97&amp;quot;, color=&amp;quot;grey&amp;quot;) +
    geom_scatterpie(data = largest, 
                    aes(lon, lat, r = sqrt(total)/2000),
                    cols = c(&amp;quot;white&amp;quot;, &amp;quot;black&amp;quot;, &amp;quot;asian&amp;quot;, &amp;quot;others&amp;quot;), 
                    alpha = 0.5) +
    scale_fill_manual(
        breaks = c(&amp;quot;white&amp;quot;, &amp;quot;black&amp;quot;, &amp;quot;asian&amp;quot;, &amp;quot;others&amp;quot;),
        labels = c(&amp;quot;white alone&amp;quot;, &amp;quot;black alone&amp;quot;, &amp;quot;asian alone&amp;quot;, &amp;quot;others&amp;quot;),
        values = c(&amp;quot;asian&amp;quot; = &amp;quot;orange&amp;quot;,
                   &amp;quot;white&amp;quot; = &amp;quot;white&amp;quot;,
                   &amp;quot;black&amp;quot; = &amp;quot;black&amp;quot;,
                   &amp;quot;others&amp;quot; = &amp;quot;cyan&amp;quot;)
    ) +
    labs(title = &amp;quot;Races in metro areas over one million population&amp;quot;,
         subtitle = &amp;quot;others includes mixed races and American indians, Alaska natives, native Hawaiians and pacific islanders&amp;quot;,
         caption = &amp;quot;Source: 2016 ACS 1-year estimate&amp;quot;,
         fill = NULL) +
    coord_fixed() +
    theme_bw() +
    theme(legend.position = c(0.96, 0.02),
          legend.justification = c(1, 0),
          panel.grid = element_blank(),
          panel.border = element_blank(),
          axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2018-01-16-create-pie-plots-on-a-map-in-r_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Determine relationship between census geographic entities with totalcensus package</title>
      <link>/2017/12/28/use-totalcensus-package-to-determine-relationship-between-geographic-entities/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/28/use-totalcensus-package-to-determine-relationship-between-geographic-entities/</guid>
      <description>&lt;p&gt;This is an application example of &lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34;&gt;totalcensus package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The geographic hierarchy primer in &lt;a href=&#34;https://www.census.gov/prod/cen2010/doc/sf1.pdf&#34;&gt;Census 2010 summary file 1 technical documentation&lt;/a&gt; displays the relationship between geographic entities. The lower one of the two entities connected by a line is entirely within the boundary of the upper one. For example, a county subdivision is always within the boundaries of a county and a school district always within the boundaries of a state. If two entities are not connected, they may not belong to each other. For example, the ZIP code tabulation areas may cross state borders though they are much smaller than states.&lt;/p&gt;
&lt;p&gt;&lt;br&gt; &lt;img src=&#34;https://s3.amazonaws.com/gl-shared-pictures/hierarchy_census_geographic_entities.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;It is easy to get the summary statistics of lower geographies within a higher one when they are connected. For example, if we want the race population of all county subdivision in Kent county, RI, we can run&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(totalcensus)
library(data.table)
library(magrittr)
sub_kent &amp;lt;- read_acs5year(
    year = 2016,
    states = &amp;quot;RI&amp;quot;,
    areas = &amp;quot;Kent county, RI&amp;quot;,
    table_contents = c(
        &amp;quot;white = B02001_002&amp;quot;,
        &amp;quot;black = B02001_003&amp;quot;,
        &amp;quot;asian = B02001_005&amp;quot;
    ),
    summary_level = &amp;quot;070&amp;quot;  # of county subdivision
)

print(sub_kent)
    #               area                  GEOID       lon      lat state population white black asian GEOCOMP SUMLEV                                                                 NAME
    # 1: Kent County, RI 07000US440031864031240 -71.73078 41.69073    RI        728   724     0     4     all    070                 Greene CDP, Coventry town, Kent County, Rhode Island
    # 2: Kent County, RI 07000US440031864099999 -71.59396 41.69140    RI      34225 32994   384   187     all    070 Remainder of Coventry town, Coventry town, Kent County, Rhode Island
    # 3: Kent County, RI 07000US440032224099999 -71.48331 41.64415    RI      13104 12120    77   404     all    070  East Greenwich town, East Greenwich town, Kent County, Rhode Island
    # 4: Kent County, RI 07000US440037430074300 -71.42452 41.71389    RI      81881 74990  1163  2237     all    070                Warwick city, Warwick city, Kent County, Rhode Island
    # 5: Kent County, RI 07000US440037772099999 -71.65790 41.62810    RI       6112  5611    26   314     all    070  West Greenwich town, West Greenwich town, Kent County, Rhode Island
    # 6: Kent County, RI 07000US440037844099999 -71.51749 41.70306    RI      28836 26196   704   806     all    070      West Warwick town, West Warwick town, Kent County, Rhode Island&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If two geographic entities are not connected by a line, how do we know, for example, how many ZIP code tabulation areas are in or partially in Boston city?&lt;/p&gt;
&lt;p&gt;The key to answer this question is that census blocks are connected to and lower than all other geographies. We can connect any two geographic entities through census blocks: if an ZIP code tabulation area and Boston city share a census block, the ZIP code is in or partially in the city. The decennial census 2010 has data down to block level, with which we can find all zip codes in Boston using &lt;code&gt;totalcensus&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;zip_boston &amp;lt;- read_decennial(
    year = 2010,
    states = &amp;quot;MA&amp;quot;,
    geo_headers = c(&amp;quot;ZCTA5&amp;quot;, &amp;quot;PLACE&amp;quot;),
    summary_level = &amp;quot;block&amp;quot;
) %&amp;gt;%
    # use search_fips(&amp;quot;boston&amp;quot;, &amp;quot;MA&amp;quot;) to find its PLACE code is &amp;quot;07000&amp;quot;
    .[PLACE == &amp;quot;07000&amp;quot;, unique(ZCTA5)] 

zip_boston
# all zip code in Boston:
    #  [1] &amp;quot;02134&amp;quot; &amp;quot;02135&amp;quot; &amp;quot;02467&amp;quot; &amp;quot;02215&amp;quot; &amp;quot;02163&amp;quot; &amp;quot;02115&amp;quot; &amp;quot;02116&amp;quot; &amp;quot;02199&amp;quot;
    #  [9] &amp;quot;02108&amp;quot; &amp;quot;02114&amp;quot; &amp;quot;02113&amp;quot; &amp;quot;02109&amp;quot; &amp;quot;02110&amp;quot; &amp;quot;02203&amp;quot; &amp;quot;02129&amp;quot; &amp;quot;02128&amp;quot;
    # [17] &amp;quot;02127&amp;quot; &amp;quot;02210&amp;quot; &amp;quot;02118&amp;quot; &amp;quot;02111&amp;quot; &amp;quot;02119&amp;quot; &amp;quot;02120&amp;quot; &amp;quot;02130&amp;quot; &amp;quot;02121&amp;quot;
    # [25] &amp;quot;02125&amp;quot; &amp;quot;02122&amp;quot; &amp;quot;02124&amp;quot; &amp;quot;02126&amp;quot; &amp;quot;02131&amp;quot; &amp;quot;02132&amp;quot; &amp;quot;02136&amp;quot; &amp;quot;99999&amp;quot;
    # [33] &amp;quot;02152&amp;quot; &amp;quot;02151&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s read race population by zip code in or partially in Boston city from the latest 2016 ACS 5-year survey.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read data for all zip code
race_zip_boston &amp;lt;- read_acs5year(
    year = 2016,
    states = &amp;quot;US&amp;quot;,   # ZCTA5 only in national files
    geo_headers = &amp;quot;ZCTA5&amp;quot;,
    table_contents = c(
        &amp;quot;white = B02001_002&amp;quot;,
        &amp;quot;black = B02001_003&amp;quot;,
        &amp;quot;asian = B02001_005&amp;quot;
    ),
    summary_level = &amp;quot;860&amp;quot;  # of ZCTA5
) %&amp;gt;%
    # select zip codes in or partially in Boston city
    .[ZCTA5 %in% zip_boston]

head(race_zip_boston, 3)
     #           GEOID       lon      lat ZCTA5 state population white black asian GEOCOMP SUMLEV        NAME
     # 1: 86000US02108 -71.06485 42.35777 02108    NA       4049  3515   209   172     all    860 ZCTA5 02108
     # 2: 86000US02109 -71.05063 42.36722 02109    NA       4015  3497   135   249     all    860 ZCTA5 02109
     # 3: 86000US02110 -71.04785 42.36196 02110    NA       2124  1814    83   206     all    860 ZCTA5 02110&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s examine another example: congressional districts (CD for 111th congress) and state legislative districts (SLDU for Upper Chamber year 1 and SLDL for Lower Chamber year 1). Both CD and SLDs descend from states but do not belong to each other. Usually SLDs are smaller than CD. So which SLDs are in or partially in each CD? Again, we can connect CD and SLD with census blocks using decennial census 2010 data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vote_RI &amp;lt;- read_decennial(
    year = 2010,
    states = &amp;quot;RI&amp;quot;,
    geo_headers = c(&amp;quot;CD&amp;quot;, &amp;quot;SLDU&amp;quot;, &amp;quot;SLDL&amp;quot;),
    summary_level = &amp;quot;block&amp;quot;
) %&amp;gt;%
    .[, .(SLDU = list(unique(SLDU)), SLDL = list(unique(SLDL))), by = CD] 

# each CD contains a vector of SLDUs and a vector of SLDLs
    #    CD                             SLDU                             SLDL
    # 1: 01  c(009,011,010,012,013,023, ...)  c(066,067,069,068,072,075, ...)
    # 2: 02  c(024,033,035,031,029,028, ...)  c(040,026,028,025,029,027, ...)&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Proccess 5-digit ZIP Code Tabulation Area (ZCTA5) data with totalcensus package</title>
      <link>/2017/12/23/census_data_zip_code/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/23/census_data_zip_code/</guid>
      <description>&lt;p&gt;This is an example of applications of &lt;code&gt;totalcensus&lt;/code&gt; package. To install the package, follow the instructions at &lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34; class=&#34;uri&#34;&gt;https://github.com/GL-Li/totalcensus&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this example, we examine data related to 5-digit ZIP Code Tabulation Area (ZCTA5), using 2016 ACS 5-year survey summary files. Let’s first load the libraries and then answer a couple questions related to zip code&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(totalcensus)
library(data.table)
library(magrittr)
library(ggplot2)
library(ggmap)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;whats-the-population-in-a-zcta5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What’s the population in a ZCTA5&lt;/h3&gt;
&lt;p&gt;These population data can be easily obtained with the code below. There are 32898 ZCTA5s in the United States and a ZCTA5 has an average population of 9656 and a median population of 2780. The population distribution is highly skewed towards zero with 320 of them having no people living in and 1583 having population below 100. There are 252 zip code having population over 65000.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read population in each zip code
zip_population &amp;lt;- read_acs5year(
    year = 2016,
    states = &amp;quot;US&amp;quot;,
    geo_headers = &amp;quot;ZCTA5&amp;quot;,
    summary_level = &amp;quot;860&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Reading US 2016 ACS 5-year survey geography file&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(zip_population$population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       0     714    2780    9656   13040  115104&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;median-age-in-a-zcta5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Median age in a ZCTA5&lt;/h3&gt;
&lt;p&gt;Just for fun, let’s find out the median age of population living in each ZCTA5. The result is pretty interesting. After removing those ZCTA5s with population below 1000 and those with larger margin of error in median age estimate and population count, the smallest median age of a ZCTA5 is 19 and largest is 75.50. These numbers mean that some zip code tabulation area are dominated by very young people while some are dominated by very old people.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read median age 
median_age &amp;lt;- read_acs5year(
    year = 2016,
    states = &amp;quot;US&amp;quot;,
    table_contents = &amp;quot;median_age = B01002_001&amp;quot;,
    geo_headers = &amp;quot;ZCTA5&amp;quot;,
    summary_level = &amp;quot;860&amp;quot;,
    with_margin = TRUE
) %&amp;gt;%
    # only keep good age estimate and population count
    .[median_age_margin &amp;lt; 0.1 * median_age] %&amp;gt;%
    .[population_margin &amp;lt; 0.1 * population] %&amp;gt;%
    # remove ZCTA5 with population below 1000
    .[population &amp;gt; 1000]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Reading US 2016 ACS 5-year survey geography file&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(median_age$median_age)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   19.00   35.60   39.90   39.89   43.90   75.50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How are these extreme median ages possible for a zip code area which has thousands population? The young median age is easier to understand - many colleges are assigned exclusively with a zip code and the residents in this zip are mostly students living in dorms so the median age can be very low. The zip code areas with very old median age, though a surprise, are still understandable: these are the communities full of retired people.&lt;/p&gt;
&lt;p&gt;It is said that people like to go to South for warm weather after retirement. Can we see this from the median age data? Yes, old people went Florida!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download US map
us_map &amp;lt;- get_map(&amp;quot;US&amp;quot;, zoom = 4, color = &amp;quot;bw&amp;quot;)

# plot ZCTA5 with 65 or up median age on map
ggmap(us_map) + 
    geom_point(data = median_age[median_age &amp;gt; 65], 
               aes(lon, lat, size = population),
               color = &amp;quot;red&amp;quot;,
               alpha = 0.5) +
    ylim(25, 50) +
    scale_size_area(max_size = 3) +
    labs(
        title = &amp;quot;ZIP code area with median age above 65&amp;quot;,
        caption = &amp;quot;Source: 2016 ACS 5-year survey&amp;quot;,
        x = NULL,
        y = NULL
    ) +
    theme(
        axis.text = element_blank(),
        axis.ticks = element_blank()
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-12-23-use-totalcensus-package-to-extract-block-level-data-of-boston-grouped-by-zip-code_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Build a R package for yourself</title>
      <link>/2017/09/14/build-a-r-package-for-yourself/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/14/build-a-r-package-for-yourself/</guid>
      <description>&lt;p&gt;A R user can benefit a lot from building packages. I have read people writing about the benefit in various occasions and cannot agree more after building my first package. We don’t have to a be R developer to write packages. Developers write packages for others; we can just write packages for ourselves. As a R user, we must have written functions and collected datasets, and may have used them across projects or may want to use them later on. The conventional way to reuse functions is to copy and paste them to the new project or to load them by &lt;code&gt;source(xxx.R)&lt;/code&gt;, and the conventional way to reuse datasets it to load &lt;code&gt;.Rdata&lt;/code&gt; files which store the datasets. We will have to know where the functions and datasets are stored, which is not a easy job if we have a large collection. By building functions and datasets into a package, we keep them in one place and use them the same way as using any other packages. With the help of package documentation, these functions and datasets become our great asset.&lt;/p&gt;
&lt;p&gt;Building a R packages is actually far more easier than a R user could have expected. In RStudio, it is nothing but writing normal R code with formatted comments. If this package is just for ourselves, we can save the hassle of publishing it on github or CRAN.&lt;/p&gt;
&lt;p&gt;Below are step by step instructions of building a working package in RStudio. There are many great tutorials for building R packages. I try to make this one to be the simplest and most up to date.&lt;/p&gt;
&lt;div id=&#34;prepare-for-a-new-package-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare for a new package project&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Step 1 - install necessary packages&lt;/strong&gt; Update RStudio if it is very old. Start RStudio and install package &lt;code&gt;roxygen2&lt;/code&gt;. This package simplifies package documentation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;roxygen2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 2 - create a new package&lt;/strong&gt; From RStudio menu, click file then new project and choose to create project in a new directory. Select creating R package and name the package, for example, as &lt;code&gt;mytoolbox&lt;/code&gt; and place it in the directory of our choice. RStudio automatically creates several subdirectories and files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3 - allow roxygen2 to take care of documentation&lt;/strong&gt; From RStudio menu click build then configure build tools, verify package is selected in Project build tools, check the box for Generate documentation with roxygen, in the popup dialogue box check all boxes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 4 - delete NAMESPACE file&lt;/strong&gt; to clear way for &lt;code&gt;roxygen2&lt;/code&gt; to automatically generate this file. Otherwise we will get a warning when building the package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-functions-to-the-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Add functions to the package&lt;/h2&gt;
&lt;p&gt;Create a &lt;code&gt;.R&lt;/code&gt; files for a function and save it in subdirectory &lt;code&gt;/R&lt;/code&gt;. A good practice is to have only one function in a &lt;code&gt;.R&lt;/code&gt; file. We can have as many files as needed for all functions under subdirectory &lt;code&gt;/R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;.R&lt;/code&gt; file, let’s call it &lt;code&gt;mess_up_function.R&lt;/code&gt;, has two sections, as shown in the example code below. The first is the Roxygen comment section, of which each line starts with &lt;code&gt;#&#39;&lt;/code&gt;. Roxygen2 generates documentation of the function from these comments. Most tags in the comment section are self-explanatory, for example &lt;code&gt;@para&lt;/code&gt; for parameters and &lt;code&gt;@examples&lt;/code&gt; for examples. Pay attention to these three tags: 1) &lt;code&gt;#&#39; @export&lt;/code&gt; exports the function for package users. 2) &lt;code&gt;#&#39; @import package_name&lt;/code&gt; or &lt;code&gt;#&#39; @importFrom package_name function_1 function_2&lt;/code&gt; are to import whole packages or selected functions, depending on how we use these packages in building our own package. Import the whole package if we use many functions in the package; import only selected functions if we know we only need them.&lt;/p&gt;
&lt;p&gt;The second section is the R code where we define our function. This section is standard R code with one exception: never use &lt;code&gt;library(pkg_name)&lt;/code&gt; or &lt;code&gt;require(pkg_name)&lt;/code&gt; to load packages, as they may mess up with name space. Instead, use &lt;code&gt;#&#39; @import&lt;/code&gt; or &lt;code&gt;#&#39; @importFrom&lt;/code&gt; as discussed in the Roxygen comment section, or use &lt;code&gt;pkg_name::func()&lt;/code&gt;. The later method takes extra 4 microseconds for each run, which is acceptable for processing small datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; mess up function (This is the title.)
#&amp;#39; 
#&amp;#39; @description This function mess up with two strings by extracting vowels from
#&amp;#39; the first string and attaching them to the second.
#&amp;#39;
#&amp;#39; @param string_1 the first string
#&amp;#39; @param string_2 the second string
#&amp;#39; 
#&amp;#39; @return a string 
#&amp;#39;
#&amp;#39; @examples
#&amp;#39; # example 1
#&amp;#39; mess_up(&amp;quot;The United States&amp;quot;, &amp;quot;Russia&amp;quot;)
#&amp;#39; 
#&amp;#39; # example 2
#&amp;#39; mess_up(&amp;quot;Barack Obama&amp;quot;, &amp;quot;Donald Trump&amp;quot;)

#&amp;#39; @export
#&amp;#39; 
#&amp;#39; @importFrom stringr str_extract_all


mess_up &amp;lt;- function(string_1, string_2){
    ## This function extract vowels from string_1 and place it 
    ## at the end of string_2
    vowels &amp;lt;- str_extract_all(string_1, &amp;quot;[AEIOUaeiou]&amp;quot;)[[1]]
    vowels &amp;lt;- paste0(vowels, collapse = &amp;quot;&amp;quot;)
    paste0(string_2, vowels, collapse = &amp;quot;&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;add-a-dataset-to-the-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Add a dataset to the package&lt;/h2&gt;
&lt;div id=&#34;save-dataset-in-subdirectory-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;save dataset in subdirectory &lt;code&gt;/data&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This dataset can be a vector, a list, a data frame, or a data.table. Let’s call it &lt;code&gt;my_dataset&lt;/code&gt;. To add it to the package, simply save it as a &lt;code&gt;.RData&lt;/code&gt; file to the subdirectory &lt;code&gt;/data&lt;/code&gt; of the package by running&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# one .RData file has ONLY one dataset
save(my_dataset, file = &amp;quot;path_to_package/data/my_dataset.RData&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-.r-file-in-subdirectory-r-to-document-the-dataset&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;create a &lt;code&gt;.R&lt;/code&gt; file in subdirectory &lt;code&gt;/R&lt;/code&gt; to document the dataset&lt;/h3&gt;
&lt;p&gt;This dataset is ready to use, but a good practice is always to have a documentation for it. We can make a &lt;code&gt;doc_my_dataset.R&lt;/code&gt; file for data documentation. The file is almost completely Roxygen comments. The only line of non-comment code is the name of the dataset in quotation &lt;code&gt;&amp;quot;my_dataset&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; Here is the title of the dataset
#&amp;#39;
#&amp;#39; @description More description of the dataset is here
#&amp;#39;
#&amp;#39; @docType data
#&amp;#39;
#&amp;#39; @usage data(&amp;quot;my_dataset&amp;quot;)
#&amp;#39;
#&amp;#39; @format data.frame
#&amp;#39;
#&amp;#39; @keywords datasets
#&amp;#39;
#&amp;#39; @source This is a link to 
#&amp;#39; \href{http://www.xxx.xxx.com/xxx.csv}{the origin data}
#&amp;#39;

&amp;quot;my_dataset&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-the-description-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set up the DESCRIPTION file&lt;/h2&gt;
&lt;p&gt;This file mostly provides general information of the package. Many of them we may not care if we just write the package for ourselves. But two items are important: 1) If we want to load our dataset whenever loading the package, keep &lt;code&gt;LazyData: true&lt;/code&gt;. 2) Place all other packages used in the package under &lt;code&gt;Imports&lt;/code&gt;. In case others want to install this package, these packages will be installed automatically.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Package: my_package_name
Type: Package
Title: Title of package 
Version: 0.1.2
Author: my name
Maintainer: my name &amp;lt;myemail@xxx.com&amp;gt;
Description: Give a little bit more detailed description of the package which can 
    span multiple lines. 
License: your_choice
Encoding: UTF-8
LazyData: true
Imports:
    stringr (&amp;gt;= 1.2.0), 
    ggplot2 (&amp;gt;= 2.0.0)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-the-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Build the package&lt;/h2&gt;
&lt;p&gt;The last step is to build the package, which is very easy in RStudio. From the menu select Build and then Build and Reload. RStudio will take care of all that follow. After the package is successfully built, we can use this package as any other package in our work with &lt;code&gt;library(mytoolbox)&lt;/code&gt; and enjoy the easy access to our functions and datasets.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Extract US Census 2010 data with data.table and dplyr</title>
      <link>/2017/08/29/process-2010-census-data-with-data-table/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/29/process-2010-census-data-with-data-table/</guid>
      <description>&lt;p&gt;This post explains how to extract information from the original dataset of the US 2010 census summary file 1 with urban/rural update, using data.table or dplyr package in R.&lt;/p&gt;
&lt;p&gt;Why do we want to work with the original data? You may ask, when there are already R packages, such as UScensus2010, censusapi, and tidycensus, which help user get the data.&lt;/p&gt;
&lt;p&gt;The biggest benefit is that you will have full access to all the census 2010 data. The total size of the US 2010 national census summary 1 file with urban/rural update is nearly 150Gb, which is too heavy to be included as dataset in a package. The stand-alone UScensus2010 package only delivers selected demographic data. Others provide an access to United States Census Bureau’s APIs, which also offers selected data. By dealing with the original data directly, you can extract whatever data you want.&lt;/p&gt;
&lt;p&gt;In recent years, fast development of packages data.table and dplyr makes it possible for R to process original 2010 census data in a reasonable time frame. In the following example, I retrieved the latitude, longitude, population of all race and of black people living in each census block in the city of South Bend Indiana. The whole process takes about 4 seconds on a four years old laptop. With these data in hand we can plot nicely where black people live down to census block level on a map downloaded from GoogleMap. In a city most census blocks are equivalent to street blocks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-29-process-2010-census-data-with-data-table_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This post is organized in this order: I will first give a brief introduction to the 2010 census summary file 1 with urban/rural update. Then I will show how to extract data step by step using R and data.table package with the example shown above. The codes are verbose in this section as I want to show the details. To clean it up I will then give a more concise codes that use pipe operator from magrittr package. As many users are more familiar with dplyr package, I will also translate the data.table code to dplyr code. The dplyr approach is sufficiently fast for most applications.&lt;/p&gt;
&lt;div id=&#34;file-structure-of-the-census-2010-summary-1-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;File structure of the census 2010 summary 1 file&lt;/h2&gt;
&lt;p&gt;The 2010 census data with urban/rural update can be downloaded from &lt;a href=&#34;https://www2.census.gov/census_2010/04-Summary_File_1/Urban_Rural_Update/&#34;&gt;United States Census Bureau official site&lt;/a&gt;. The total size is nearly 150 GB so make sure you have enough hard drive space for it. The data is split into 50 states and DC. Click on a state, for example, Indiana, there is a file named in2010.ur1.zip. Download this file and unzip it to a folder named with the abbreviation “IN”. Do this for all other state and DC.&lt;/p&gt;
&lt;p&gt;Inside the folder “IN/” there are a geographic header record file named &lt;code&gt;ingeo2010.ur1&lt;/code&gt; and 48 data files named as &lt;code&gt;in000012010.ur1&lt;/code&gt;, &lt;code&gt;in000022010.ur1&lt;/code&gt;, …, &lt;code&gt;in000482010.ur1&lt;/code&gt;. The first two characters &lt;code&gt;in&lt;/code&gt; is the abbreviation of Indiana. The file extension &lt;code&gt;ur1&lt;/code&gt; stands for summary file &lt;strong&gt;1&lt;/strong&gt; with &lt;strong&gt;u&lt;/strong&gt;rban &lt;strong&gt;r&lt;/strong&gt;ural update. The last four numbers &lt;code&gt;2010&lt;/code&gt; before file extension indicate the census year 2010. The numbers &lt;code&gt;00001&lt;/code&gt;, &lt;code&gt;00002&lt;/code&gt;, …, and &lt;code&gt;00048&lt;/code&gt; are the sequence of the files. These files are called &lt;code&gt;file 01&lt;/code&gt;, &lt;code&gt;file 02&lt;/code&gt;, …, and &lt;code&gt;file 48&lt;/code&gt; in the &lt;a href=&#34;https://www.census.gov/prod/cen2010/doc/sf1.pdf&#34;&gt;techinical documentation of the summary file 1&lt;/a&gt;. The documentation is our dictionary in using these files and we will talk more about it later.&lt;/p&gt;
&lt;p&gt;The geographic header record file &lt;code&gt;ingeo2010.ur1&lt;/code&gt; contains the geographic information. It has 331556 lines; each line corresponds to a geographic entity in the census data of Indiana. A geographic entity can be a state, a county, a city, a census tract, a census block etc. A line can be up to 500 characters long, including spaces. Unique to each line is the logical record number, which is 7 characters long, located from 19 to 25 characters in a line. Page 2-8 of the technical documentation lists all geographic field in a line. Each field is assigned with a short reference code. Here are list of frequently use ones:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;geographic field&lt;/th&gt;
&lt;th&gt;reference&lt;/th&gt;
&lt;th&gt;starting position&lt;/th&gt;
&lt;th&gt;ending position&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;logical record number&lt;/td&gt;
&lt;td&gt;LOGRECNO&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;summary level&lt;/td&gt;
&lt;td&gt;SUMLEV&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;geographic component&lt;/td&gt;
&lt;td&gt;GEOCOMP&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;county FIPS&lt;/td&gt;
&lt;td&gt;COUNTY&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;place FIPS&lt;/td&gt;
&lt;td&gt;PLACE&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Metropolitan Area FIPS&lt;/td&gt;
&lt;td&gt;CBSA&lt;/td&gt;
&lt;td&gt;113&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;internal point (latitude)&lt;/td&gt;
&lt;td&gt;INTPTLAT&lt;/td&gt;
&lt;td&gt;337&lt;/td&gt;
&lt;td&gt;347&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;internal point (longitude)&lt;/td&gt;
&lt;td&gt;INTPTLON&lt;/td&gt;
&lt;td&gt;348&lt;/td&gt;
&lt;td&gt;359&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The data files contain the recorded census data. They are &lt;code&gt;.csv&lt;/code&gt; files, that is, each data field is separated by a comma. For example, file 02 contains the population in urban and rural area. Its 5th field is the logical record number that matches the geographic header record file. The 6th field is total population, 7th field urban population, 8th field population in urbanized area, … The properties of each field is listed in the technical documentation. If you want to know the details of, for example file 17, just search in the pdf file of the technical documentation for “file 17” and read through the description.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extract-the-2010-census-data-step-by-step&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extract the 2010 census data step by step&lt;/h2&gt;
&lt;p&gt;Say we are interested in the population and race in the city of South Bend, Indiana and we want to plot these data on a map at census block level, what should we do? I will use this as an example to show how to extract 2010 census data in detail.&lt;/p&gt;
&lt;div id=&#34;read-and-extract-geographic-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read and extract geographic data&lt;/h3&gt;
&lt;p&gt;Let’s first take a look at the geographic header record file. We convert it to a data.table of which each row is a line in the file. Each line is a string of characters without separator, so we read it into only one column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
# change path to data based on your local directories
geo_file &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/ingeo2010.ur1&amp;quot;), 
                  sep = &amp;quot;\n&amp;quot;, 
                  header = FALSE)
# show total number of lines
dim(geo_file)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 331556      1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# display the first line
head(geo_file, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                                                                                                                                                                                                                                                                                                                                                               V1
## 1: UR1ST IN04000000  00000012318                                                                                                                                                                            92789193658    1537004191Indiana                                                                                   AN  6483802  2795541+39.9030256-086.283950300            00448508&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This file has 331556 lines. There are many blank spaces in a line as a geographic entity usually does not have all the geographic fields.&lt;/p&gt;
&lt;p&gt;We want get the logical record number, which is used to match those in data file, and latitude and longitude for plot in map. We want to keep the FIPS of place so that later on we can locate South Bend city with its FIPS number. We also want keep summary levels as we only want data at census blocks level. The references of geographic fields are used as column names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;geo &amp;lt;- geo_file[, .(LOGRECNO = as.numeric(substr(V1, 19, 25)),
                    SUMLEV = substr(V1, 9, 11),
                    PLACE = substr(V1, 46, 50),
                    INTPTLAT = as.numeric(substr(V1, 337, 347)),
                    INTPTLON = as.numeric(substr(V1, 348, 359)))]
geo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         LOGRECNO SUMLEV PLACE INTPTLAT  INTPTLON
##      1:        1    040       39.90303 -86.28395
##      2:        2    040       40.13668 -86.23489
##      3:        3    040       40.43883 -86.21876
##      4:        4    040       40.12984 -86.21021
##      5:        5    040       39.92054 -86.27358
##     ---                                         
## 331552:   331552    970       41.63835 -85.55221
## 331553:   331553    970       41.67686 -87.49205
## 331554:   331554    970       41.15086 -85.66872
## 331555:   331555    970       39.35130 -86.03878
## 331556:   331556    970       41.63419 -87.20929&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The column &lt;code&gt;PLACE&lt;/code&gt; has a lot of missing values, as many geographic entities does not belong to any place.&lt;/p&gt;
&lt;p&gt;Now we can extract geographic data of South Bend. An easy way to find its FIPS number is from &lt;a href=&#34;https://en.wikipedia.org/wiki/South_Bend,_Indiana&#34;&gt;its Wikipedia page&lt;/a&gt;. South Bend’s FIPS is 18-71000. The first two digits are the FIPS of Indiana, so the unique FIPS in Indiana for South Bend is 71000. Let’s keep only the rows for South Bend (sb).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sb_geo &amp;lt;- geo[PLACE == &amp;quot;71000&amp;quot;]
sb_geo&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       LOGRECNO SUMLEV PLACE INTPTLAT  INTPTLON
##    1:   241621    070 71000 41.61875 -86.24093
##    2:   241622    080 71000 41.63354 -86.22549
##    3:   241623    085 71000 41.63354 -86.22549
##    4:   241624    091 71000 41.63525 -86.21833
##    5:   241625    090 71000 41.63525 -86.21833
##   ---                                         
## 5461:   321382    614 71000 41.72872 -86.26427
## 5462:   324739    624 71000 41.70951 -86.20096
## 5463:   324774    624 71000 41.66799 -86.23096
## 5464:   324810    624 71000 41.66797 -86.27524
## 5465:   324851    624 71000 41.70286 -86.27826&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This geographic data includes all summary levels. As we only want the census block level data, we further filter with &lt;code&gt;SUMLEV == &amp;quot;100&amp;quot;&lt;/code&gt;. At this stage we get the geographic data we want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sb_block &amp;lt;- sb_geo[SUMLEV == &amp;quot;100&amp;quot;]
sb_block&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       LOGRECNO SUMLEV PLACE INTPTLAT  INTPTLON
##    1:   241626    100 71000 41.63613 -86.21864
##    2:   241627    100 71000 41.63670 -86.21659
##    3:   241628    100 71000 41.63573 -86.22172
##    4:   241629    100 71000 41.63182 -86.22022
##    5:   241630    100 71000 41.63367 -86.22093
##   ---                                         
## 5002:   252566    100 71000 41.69486 -86.25132
## 5003:   252567    100 71000 41.69649 -86.25815
## 5004:   253091    100 71000 41.73058 -86.35508
## 5005:   253092    100 71000 41.73035 -86.35565
## 5006:   253093    100 71000 41.72831 -86.35573&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Are we sure we get the correct geographic data? We can plot the latitude and longitude directly on a map. From the map below you will also get a sense of what a census block is; it is basically a street block in urban area. We need internet connection to download map data from Google Map.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmap)
map &amp;lt;- get_map(&amp;quot;south bend, indiana&amp;quot;, zoom = 13)
ggmap(map) +
    geom_point(data = sb_block, aes(INTPTLON, INTPTLAT), color = &amp;quot;red&amp;quot;, alpha = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-29-process-2010-census-data-with-data-table_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-and-extract-population-and-race-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read and extract population and race data&lt;/h3&gt;
&lt;p&gt;From the technical documentation we know that population and race information is in file 03. So let’s read this file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f03 &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/in000032010.ur1&amp;quot;), header = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 84.5% of 331556 rows
Read 331556 rows and 199 (of 199) columns from 0.134 GB file in 00:00:03&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# number of rows and columns
dim(f03)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 331556    199&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It has 199 columns; which ones are what we want? We still go back to the technical documentation, page 6-22, and read the description for file 03. The 5th field is logical record number, 6th the total population data and 8th the black population data. Each population data field also has a reference but is hard to follow. For clarity we name these column in plain English. So all the data we need in Indiana is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;population &amp;lt;- f03[, .(LOGRECNO = V5,
                      total_popul = V6,
                      black_popul = V8)]
population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         LOGRECNO total_popul black_popul
##      1:        1     6483802      591397
##      2:        2     4697100      580128
##      3:        3     3836584      560288
##      4:        4      860516       19840
##      5:        5     1786702       11269
##     ---                                 
## 331552:   331552       18918          24
## 331553:   331553        4636         154
## 331554:   331554       10537          25
## 331555:   331555         560         100
## 331556:   331556           0           0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here it is easy to get the population in South Bend at census block level: just join the data to &lt;code&gt;sb_block&lt;/code&gt; by logical record number:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sb_block_popl &amp;lt;- population[sb_block, on = .(LOGRECNO)]
sb_block_popl&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       LOGRECNO total_popul black_popul SUMLEV PLACE INTPTLAT  INTPTLON
##    1:   241626          28          10    100 71000 41.63613 -86.21864
##    2:   241627           0           0    100 71000 41.63670 -86.21659
##    3:   241628          52          16    100 71000 41.63573 -86.22172
##    4:   241629         279          21    100 71000 41.63182 -86.22022
##    5:   241630          42           1    100 71000 41.63367 -86.22093
##   ---                                                                 
## 5002:   252566          64           0    100 71000 41.69486 -86.25132
## 5003:   252567           0           0    100 71000 41.69649 -86.25815
## 5004:   253091           0           0    100 71000 41.73058 -86.35508
## 5005:   253092           0           0    100 71000 41.73035 -86.35565
## 5006:   253093           0           0    100 71000 41.72831 -86.35573&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is no need to keep the blocks where there are no people lives.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sb_block_popul &amp;lt;- sb_block_popl[total_popul &amp;gt; 0]
sb_block_popul&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       LOGRECNO total_popul black_popul SUMLEV PLACE INTPTLAT  INTPTLON
##    1:   241626          28          10    100 71000 41.63613 -86.21864
##    2:   241628          52          16    100 71000 41.63573 -86.22172
##    3:   241629         279          21    100 71000 41.63182 -86.22022
##    4:   241630          42           1    100 71000 41.63367 -86.22093
##    5:   241631          48           3    100 71000 41.63525 -86.21833
##   ---                                                                 
## 3780:   252543          75           6    100 71000 41.66027 -86.32578
## 3781:   252551          36           0    100 71000 41.69367 -86.24275
## 3782:   252559         360          11    100 71000 41.69560 -86.25924
## 3783:   252561          14           0    100 71000 41.69583 -86.25781
## 3784:   252566          64           0    100 71000 41.69486 -86.25132&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-on-map-at-block-level&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;plot on map at block level&lt;/h3&gt;
&lt;p&gt;Now we can plot total and black population on the map. This is the same map we saw at the beginning of the post. It is not shown here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(map) +
    geom_point(data = sb_block_popul, 
               aes(INTPTLON, INTPTLAT, size = total_popul,  color = &amp;quot;red&amp;quot;), 
               alpha = 0.6) +
    # remove row with 0 black population, otherwise show a small dot
    geom_point(data = sb_block_popul[black_popul &amp;gt; 0], 
               aes(INTPTLON, INTPTLAT, size = black_popul, color = &amp;quot;blue&amp;quot;), 
               alpha = 0.6) +
    scale_size_area(breaks = c(1, 50, 100, 300, 600, 1000)) +
    scale_color_identity(guide = &amp;quot;legend&amp;quot;, 
                         breaks = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;),
                         label = c(&amp;quot;all&amp;quot;, &amp;quot;black&amp;quot;)) +
    labs(color = &amp;quot;race&amp;quot;, size = &amp;quot;population&amp;quot;) +
    guides(size = guide_legend(override.aes = list(shape = 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-concise-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More concise code&lt;/h2&gt;
&lt;div id=&#34;the-data.table-way&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;the data.table way&lt;/h3&gt;
&lt;p&gt;The above codes that select South Bend data can be squeezed with pipe operator &lt;code&gt;%&amp;gt;%&lt;/code&gt; to get rid of intermediate variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(magrittr)

## An example to retrieve and plot the total and black population at the census
## black level of the city South Bend in Indiana

# the directory holding all census 2010 data
path_to_data &amp;lt;- &amp;quot;~/dropbox_datasets/US_2010_census/&amp;quot;

# geographic record of South Bend (sb) at census block level
sb_block &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/ingeo2010.ur1&amp;quot;), sep = &amp;quot;\n&amp;quot;, 
                  header = FALSE) %&amp;gt;%
    .[, .(LOGRECNO = as.numeric(substr(V1, 19, 25)),
          SUMLEV = substr(V1, 9, 11),
          PLACE = substr(V1, 46, 50),
          INTPTLAT = as.numeric(substr(V1, 337, 347)),
          INTPTLON = as.numeric(substr(V1, 348, 359)))] %&amp;gt;%
    .[PLACE == &amp;quot;71000&amp;quot; &amp;amp; SUMLEV == &amp;quot;100&amp;quot;]

# total and black population of South Bend at census block level
sb_block_popul &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/in000032010.ur1&amp;quot;), 
                       header = FALSE) %&amp;gt;%
    .[, .(LOGRECNO = V5,
          total_popul = V6,
          black_popul = V8)] %&amp;gt;%
    .[sb_block, on = .(LOGRECNO)] %&amp;gt;%
    .[total_popul &amp;gt; 0]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dplyr-approach&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;the dplyr approach&lt;/h3&gt;
&lt;p&gt;We still use data.table’s &lt;code&gt;fread()&lt;/code&gt; to read the data but use dplyr functions to process data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(dplyr)
path_to_data &amp;lt;- &amp;quot;~/dropbox_datasets/US_2010_census/&amp;quot;

sb_block &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/ingeo2010.ur1&amp;quot;), sep = &amp;quot;\n&amp;quot;, 
                  header = FALSE) %&amp;gt;%
    transmute(
        LOGRECNO = as.numeric(substr(V1, 19, 25)),
        SUMLEV = substr(V1, 9, 11),
        PLACE = substr(V1, 46, 50),
        INTPTLAT = as.numeric(substr(V1, 337, 347)),
        INTPTLON = as.numeric(substr(V1, 348, 359))
    ) %&amp;gt;%
    filter(PLACE == &amp;quot;71000&amp;quot; &amp;amp; SUMLEV == &amp;quot;100&amp;quot;)

sb_block_popul &amp;lt;- fread(paste0(path_to_data, &amp;quot;IN/in000032010.ur1&amp;quot;), header = FALSE) %&amp;gt;%
    transmute(
        LOGRECNO = V5,
        total_popul = V6,
        black_popul = V8
    ) %&amp;gt;%
    right_join(sb_block, by = &amp;quot;LOGRECNO&amp;quot;) %&amp;gt;%
    filter(total_popul &amp;gt; 0)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ggplot2: place text at right location</title>
      <link>/2017/08/18/place-text-at-right-location/</link>
      <pubDate>Fri, 18 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/18/place-text-at-right-location/</guid>
      <description>&lt;p&gt;A common task in plotting is adding texts as labels or annotations to specific locations. &lt;code&gt;ggplot()&lt;/code&gt; has functions &lt;code&gt;geom_text()&lt;/code&gt;, &lt;code&gt;geom_label()&lt;/code&gt; and &lt;code&gt;annotate()&lt;/code&gt; for this purpose. In this post we discuss how &lt;code&gt;ggplot2&lt;/code&gt; controls positioning of text.&lt;/p&gt;
&lt;p&gt;First we need to specify &lt;code&gt;(x, y)&lt;/code&gt; coordinate in the plot where the text is placed. By default, the center of the text is at &lt;code&gt;(x, y)&lt;/code&gt;, which is sometimes not what we want, as shown in the example below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
df &amp;lt;- data.frame(x = 1:3, 
                 y = 1:3, 
                 z = c(&amp;quot;aa\nnew line&amp;quot;, &amp;quot;bb\nnew line 1\nand new line 2&amp;quot;, &amp;quot;cc&amp;quot;))
g &amp;lt;- ggplot(df, aes(x = x, y = y)) +
    geom_col() +
    geom_point(color = &amp;quot;red&amp;quot;) +
    coord_cartesian(xlim = c(0.3, 3.5), ylim = c(0.5, 3.5))
g + geom_text(aes(label = z)) +
    labs(subtitle = &amp;quot;(x, y) set the position of text but often is not we want&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-18-place-object-at-right-location_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As the text has its own shape and size, we need to determine which part of the text to be superimposed at &lt;code&gt;(x, y)&lt;/code&gt;. This positioning is controlled by parameters &lt;code&gt;hjust&lt;/code&gt; and &lt;code&gt;vjust&lt;/code&gt;. Imaging the text is surrounded by a rectangle and a local coordinate originates at the bottom left corner of the rectangle, &lt;code&gt;(hjust, vjust)&lt;/code&gt; then is a local position in the local coordinate. By default, &lt;code&gt;hjust = 0.5&lt;/code&gt; and &lt;code&gt;vjust = 0.5&lt;/code&gt;, that is, the center of the rectangle is at &lt;code&gt;(x, y)&lt;/code&gt;. We can change them to match to &lt;code&gt;(x, y)&lt;/code&gt; by borders or corners, as shown in the examples below. The positioning of text is still not ideal as it is too close to &lt;code&gt;(x, y)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(gridExtra)

g1 &amp;lt;- g + geom_text(aes(label = z), hjust = 0) +
    labs(subtitle = &amp;quot;hjust = 0 place left side of the text to (x, y)&amp;quot;)
g2 &amp;lt;- g + geom_text(aes(label = z), vjust = 1) +
    labs(subtitle = &amp;quot;vjust = 1 place top of the text to (x, y)&amp;quot;)
g3 &amp;lt;- g + geom_text(aes(label = z), hjust = 1, vjust = 0) +
    labs(subtitle = &amp;quot;hjust = 1 and vjust = 0 place tottom\nright cornor of the text to (x, y)&amp;quot;)

grid.arrange(g1, g2, g3, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-18-place-object-at-right-location_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The parameters &lt;code&gt;nudge_x&lt;/code&gt; and &lt;code&gt;nudge_y&lt;/code&gt; shift whole text along &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; axis. With them we can add a space between text and &lt;code&gt;(x, y)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g + geom_text(aes(label = z), hjust = 0, nudge_x = 0.1) +
    labs(subtitle = &amp;quot;nudge_x = 0.1 moves text to the right by 0.1&amp;quot;)
g2 &amp;lt;- g + geom_text(aes(label = z), vjust = 1, nudge_y = -0.1) +
    labs(subtitle = &amp;quot;nudge_y = -0.1 moves text down by 0.1&amp;quot;)
g3 &amp;lt;- g + geom_text(aes(label = z), hjust = 1, vjust = 0, nudge_x = -0.1, nudge_y = 0.1) +
    labs(subtitle = &amp;quot;nudge_x = -0.1 nudge_y = 0.1 to northwest&amp;quot;)

grid.arrange(g1, g2, g3, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-18-place-object-at-right-location_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For multi-line text, we also want to adjust the line space. The line space is set by parameter &lt;code&gt;lineheight&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g + geom_text(aes(label = z), hjust = 1, vjust = 0, nudge_x = -0.1, lineheight = 0) +
    labs(subtitle = &amp;quot;lineheight = 0&amp;quot;)
g2 &amp;lt;- g + geom_text(aes(label = z), hjust = 1, vjust = 0, nudge_x = -0.1, lineheight = 0.9) +
    labs(subtitle = &amp;quot;lineheight = 0.9&amp;quot;)
g3 &amp;lt;- g + geom_text(aes(label = z), hjust = 1, vjust = 0, nudge_x = -0.1, lineheight = 2) +
    labs(subtitle = &amp;quot;lineheight = 2&amp;quot;)

grid.arrange(g1, g2, g3, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-18-place-object-at-right-location_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As a final note, some people use &lt;code&gt;hjust&lt;/code&gt; and &lt;code&gt;vjust&lt;/code&gt; that are &lt;code&gt;&amp;lt; 0&lt;/code&gt; or &lt;code&gt;&amp;gt; 1&lt;/code&gt; to shift text from &lt;code&gt;(x, y)&lt;/code&gt;. This works well to move up and down a single line text but not good to move left and right or multi-line text, as &lt;code&gt;hjust&lt;/code&gt; and &lt;code&gt;vjust&lt;/code&gt; are relative to dimension of the rectangle around the text. Some bad examples are shown below. So it is better to use &lt;code&gt;nudge_x&lt;/code&gt; and &lt;code&gt;nudge_y&lt;/code&gt; to shift whole text.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g1 &amp;lt;- g + geom_text(aes(label = z), vjust = 1.3) +
    labs(subtitle = &amp;quot;vjust = 1.3, more line more space&amp;quot;)
g2 &amp;lt;- g + geom_text(aes(label = z), hjust = -0.2) +
    labs(subtitle = &amp;quot;hjust = -0.1, longer lines more space&amp;quot;)

grid.arrange(g1, g2, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-18-place-object-at-right-location_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ggplot2: aes(group = ...) overrides default grouping</title>
      <link>/2017/08/13/ggplot2-group-overrides-default-grouping/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/13/ggplot2-group-overrides-default-grouping/</guid>
      <description>&lt;div id=&#34;default-grouping-in-ggplot2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Default grouping in &lt;code&gt;ggplot2&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ggplot2&lt;/code&gt; can subset all data into groups and give each group its own appearance and transformation. In many cases new users are not aware that default groups have been created, and are surprised when seeing unexpected plots.&lt;/p&gt;
&lt;p&gt;There are two ways in which &lt;code&gt;ggplot2&lt;/code&gt; creates groups implicitly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; are categorical variables, the rows with the same level form a group. Users often overlook this type of default grouping.&lt;/li&gt;
&lt;li&gt;If aesthetic mapping, such as &lt;code&gt;color&lt;/code&gt;, &lt;code&gt;shape&lt;/code&gt;, and &lt;code&gt;fill&lt;/code&gt;, map to categorical variables, they subset the data into groups. All users know these mappings create groups as data are displayed in different colors or shapes as the names suggest. Many, however, do not know that the default grouping also apply to statistic transformation such as boxplot and smooth.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s use boxplot to explain the default grouping. Boxplot displays summary statistics of a group of data. In the left figure, the &lt;code&gt;x&lt;/code&gt; axis is the categorical &lt;code&gt;drv&lt;/code&gt;, which split all data into three groups: &lt;code&gt;4&lt;/code&gt;, &lt;code&gt;f&lt;/code&gt;, and &lt;code&gt;r&lt;/code&gt;. Each group has its own boxplot. In the right figure, aesthetic mapping is included in &lt;code&gt;ggplot(..., aes(..., color = factor(year))&lt;/code&gt;. It displays data points of different years with different colors as expected. It also further split each &lt;code&gt;drv&lt;/code&gt; group into &lt;code&gt;factor(year)&lt;/code&gt; subgroups. The boxplot now applies to all the subgroups, which may or may not be what you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(grid)
library(gridExtra)

g1 &amp;lt;- ggplot(mpg, aes(drv, hwy)) +
    geom_jitter() +
    stat_boxplot(fill = NA) +
    labs(subtitle = &amp;quot;stat_boxplot runs on the default groups set by categorical drv&amp;quot;)

g2 &amp;lt;- ggplot(mpg, aes(drv, hwy, color = factor(year))) +
    geom_jitter() +
    stat_boxplot(fill = NA) +
    labs(subtitle = &amp;quot;aes(color) further divides data into more groups&amp;quot;)

grid.arrange(g1, g2, nrow = 1,
             top = textGrob(&amp;quot;Examples of default grouping created by categorical axis and aesthetic mapping&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-if-you-do-not-want-the-default-grouping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What if you do not want the default grouping&lt;/h2&gt;
&lt;p&gt;The simplest solution to remove default grouping if it is caused by aesthetic mapping: do not include the mapping in the &lt;code&gt;ggplot(aes())&lt;/code&gt; as they are inherited by all layers.&lt;/p&gt;
&lt;p&gt;In all cases we can break the default grouping with &lt;code&gt;aes(group = ...)&lt;/code&gt;. It overrides default grouping by explicitly setting the &lt;code&gt;group&lt;/code&gt;. I will demonstrate how it works using the simple examples below.&lt;/p&gt;
&lt;p&gt;We have the following data and we want connect the path of all data in &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; space. With the default grouping, the path, however, only connect within each group of &lt;code&gt;x&lt;/code&gt;, as &lt;code&gt;x&lt;/code&gt; is categorical.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# make up a simple dummy data frame
df &amp;lt;- data.frame(x = c(&amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;),
                 y = c(1, 2, 3, 4, 4, 3, 2, 1),
                 z = c(&amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;))
df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   x y z
## 1 a 1 A
## 2 a 2 A
## 3 a 3 B
## 4 a 4 B
## 5 b 4 B
## 6 b 3 B
## 7 b 2 A
## 8 b 1 A&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y)) +
    geom_point() +
    geom_path() +
    labs(subtitle = &amp;quot;x set the default groups as it is categorical&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A constant &lt;code&gt;group&lt;/code&gt; removes the default grouping. In the following code, the number &lt;code&gt;123&lt;/code&gt; can be any constant such as &lt;code&gt;1&lt;/code&gt; or &lt;code&gt;&amp;quot;abc&amp;quot;&lt;/code&gt;, and &lt;code&gt;group = 123&lt;/code&gt; can be placed outside &lt;code&gt;aes()&lt;/code&gt; as it is a constant. After removing the default grouping, &lt;code&gt;geom_path()&lt;/code&gt; treat all rows as one groups so that there is only one path.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y)) +
    geom_point() +
    geom_path(aes(group = 123)) +   # constant group can stay outside of aes()
    labs(subtitle = &amp;quot;constant group removes categorical grouping in x&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;group-is-for-collective-geoms&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Group is for collective geoms&lt;/h1&gt;
&lt;p&gt;To better understand the role of &lt;code&gt;group&lt;/code&gt;, we need to know &lt;a href=&#34;https://rpubs.com/hadley/ggplot2-toolbox&#34;&gt;individual geoms and collective geoms&lt;/a&gt;. Geom stands for geometric object. Point plotted with &lt;code&gt;geom_point()&lt;/code&gt; uses one row of data and is an individual geom. Bar plotted with &lt;code&gt;geom_col()&lt;/code&gt; is also an individual geom. A polygon consists of multiple rows of data so it is a collective geom. A boxplot is also a collective geom as it is based on the statistic transformation of many rows of data. Individual geoms only depend on one row and do not need &lt;code&gt;group&lt;/code&gt;. Collective geoms need to know groups before making plots.&lt;/p&gt;
&lt;p&gt;Line and path plot use multiple rows, which qualify them as collective geoms. They, however, retain features of individual geom: each segments can have different style. This is different from polygon, of which all segments must of the same type.&lt;/p&gt;
&lt;p&gt;Now let’s see how &lt;code&gt;group&lt;/code&gt; acts on individual geoms and collective geoms.&lt;/p&gt;
&lt;p&gt;We want to connect the path within &lt;code&gt;z&lt;/code&gt; and label them in different colors, what should we do? The first thing jumps out may be &lt;code&gt;aes(color = z)&lt;/code&gt;, but it further breaks the data into four groups, which is not unexpected as we already know how grouping works.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y, color = z)) +
    geom_point() +
    geom_path() +
    labs(subtitle = &amp;quot;x and color = z split data into 4 groups&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The correct way is to explicitly set the group with &lt;code&gt;aes(group = z)&lt;/code&gt;, which overrides the default grouping.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y, color = z)) +
    geom_point() +
    geom_path(aes(group = z)) +
    labs(subtitle = &amp;quot;group = z overrides the default grouping by x&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if we remove all default grouping with constant &lt;code&gt;group&lt;/code&gt;? It does removes all default grouping for &lt;code&gt;geom_path&lt;/code&gt; as all data points are connected with one path. It, however, preserves color of each segments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y, color = z)) +
    geom_point() +
    geom_path(aes(group = 123)) +
    labs(subtitle = &amp;quot;group = 123 removes all default grouping\nbut segments of path retain color&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This will not happen to polygon, a pure collective geom. To draw polygons into groups based on &lt;code&gt;z&lt;/code&gt;, we need to specify &lt;code&gt;group = z&lt;/code&gt; for &lt;code&gt;geom_polygon()&lt;/code&gt;. It overrides all default grouping and we get two distinct polygons.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y, color = z)) +
    geom_point() +
    geom_polygon(aes(group = z), fill = &amp;quot;grey80&amp;quot;) +
    labs(subtitle = &amp;quot;group = z overrides the default grouping by x&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Set &lt;code&gt;group = 123&lt;/code&gt; removes all the default grouping by both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;color = z&lt;/code&gt;. The new group is the one of all data. The &lt;code&gt;color&lt;/code&gt; of the segments of the polygon only takes the color of &lt;code&gt;z == &amp;quot;A&amp;quot;&lt;/code&gt; and ignores all other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df, aes(x, y, color = z)) +
    geom_point() +
    geom_polygon(aes(group = 123), fill = &amp;quot;grey80&amp;quot;) +
    labs(subtitle = &amp;quot;group = 123 removes all default grouping&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-13-ggplot2-group-overrides-default-group_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My uniform way of using ggplot2</title>
      <link>/2017/08/03/a-uniform-way-to-use-ggplot2/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/03/a-uniform-way-to-use-ggplot2/</guid>
      <description>&lt;p&gt;Just finished reading Hadley Wickham’s &lt;code&gt;ggplot2&lt;/code&gt; book, (&lt;a href=&#34;http://www.springer.com/us/book/9783319242750&#34;&gt;second eition&lt;/a&gt;). Before that I have been using &lt;code&gt;ggplot2&lt;/code&gt; for a couple of years, mainly learned by reading documentation and searching for help online.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;ggplot2&lt;/code&gt; package is a powerful and comprehensive tool for generating static plots, but I also feel it is a little bit too flexible; the same plot can be made with many different ways. This fexibility provides obvious convenience but also introduces a lot of confusion and extra burden of memorization. Being flexible is not a good feature for a lazy user like me. I just can not memorize all these different methods. What I want is an appoach that gets the job done, is easy to apply to many tasks, and does not have much to memorize. I need a uniform way to use &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here I discuss how I like to make &lt;code&gt;ggplot2&lt;/code&gt; plots. It is my personal preference. Every one can find their best way. I will give the reason why I am doing so.&lt;/p&gt;
&lt;div id=&#34;what-to-be-included-in-ggplot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What to be included in &lt;code&gt;ggplot()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Every &lt;code&gt;ggplot2&lt;/code&gt; plotting starts with the function &lt;code&gt;ggplot()&lt;/code&gt;. Typically &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;aes()&lt;/code&gt; are included as arguments. The &lt;code&gt;aes()&lt;/code&gt; can include &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and more aesthetic mapping such as &lt;code&gt;color&lt;/code&gt;, &lt;code&gt;shape&lt;/code&gt;, &lt;code&gt;fill&lt;/code&gt;, …, as in the code below,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = mpg, aes(x = displ, y = cty, color = drv, shape = year, fill = cyl))
# or to simplify
ggplot((mpg, aes(displ, cty, color = drv, shape = year, fill = cyl)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My preference for this part is to include as fewer arguments as possible, even without any argument. All these arguments are inherited by all plotting layers by default. If you want them to be used in all layers, then that is good; you save a few keystrokes. But if it is not what you want, it is where troubles hide. For example, if your want to a linear fit to all data points but has &lt;code&gt;color&lt;/code&gt; in aesthetic mapping, the fit is applied to each color. You’d better move the &lt;code&gt;color&lt;/code&gt; out of &lt;code&gt;ggplot()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
ggplot(mpg, aes(cty, hwy, color = drv)) +
    geom_point() +
    stat_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-03-a-uniform-way-to-use-ggplot2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;which-to-choose-geom_xxx-or-stat_xxx&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Which to choose, &lt;code&gt;geom_xxx()&lt;/code&gt; or &lt;code&gt;stat_xxx()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;These two functions caused a lot of headache to me. Both &lt;code&gt;geom_xxx()&lt;/code&gt; and &lt;code&gt;stat_xxx()&lt;/code&gt; plot layers. Many &lt;code&gt;geom&lt;/code&gt;s have equivalent &lt;code&gt;stats&lt;/code&gt;, such as &lt;code&gt;geom_smooth()&lt;/code&gt; and &lt;code&gt;stat_smooth()&lt;/code&gt;, &lt;code&gt;geom_bar()&lt;/code&gt; and &lt;code&gt;stat_count&lt;/code&gt;, and &lt;code&gt;geom_boxplot()&lt;/code&gt; and &lt;code&gt;stat_boxplot()&lt;/code&gt;. Even &lt;code&gt;geom_point()&lt;/code&gt; has an equivalent &lt;code&gt;stat_identity()&lt;/code&gt;. So which one to use?&lt;/p&gt;
&lt;p&gt;I like to use &lt;code&gt;geom_xxx()&lt;/code&gt; for layers that directly plot the original data and &lt;code&gt;stat_xxx()&lt;/code&gt; for layers that plot statistical transformation of the original data. The former includes &lt;code&gt;geom_point()&lt;/code&gt;, &lt;code&gt;geom_line()&lt;/code&gt;, and &lt;code&gt;geom_col()&lt;/code&gt; etc. The latter includes &lt;code&gt;stat_smooth()&lt;/code&gt;, &lt;code&gt;stat_count&lt;/code&gt;, and &lt;code&gt;stat_boxplot()&lt;/code&gt; etc. This a natural choice to me as I pay more attention to data; whenever statistical transformed data are used, I want to use it explicitly with function starting with &lt;code&gt;stat&lt;/code&gt;. Using &lt;code&gt;stat_xxx()&lt;/code&gt; has additional benefit: we can choose the right &lt;code&gt;geom&lt;/code&gt; as desired without losing sense of what data are being displayed. In the following code, the counts of &lt;code&gt;drv&lt;/code&gt; are displayed as bar, point and line. No matter what &lt;code&gt;geom&lt;/code&gt; you choose, the &lt;code&gt;stat_count&lt;/code&gt; always explicitly tells you that you are plotting the count.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(drv)) +
    stat_count(geom = &amp;quot;bar&amp;quot;, fill = &amp;quot;grey70&amp;quot;) +
    stat_count(geom = &amp;quot;point&amp;quot;, size = 6, color = &amp;quot;blue&amp;quot;) +
    stat_count(geom = &amp;quot;line&amp;quot;, aes(group = 1), color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-03-a-uniform-way-to-use-ggplot2_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A few words about bar plot. Above count of one categorical variable are often plotted with &lt;code&gt;geom_bar()&lt;/code&gt;. The awkward thing is that &lt;code&gt;geom_bar(stat = &amp;quot;identity&amp;quot;)&lt;/code&gt; also make bar plot when two variables &lt;code&gt;aes(x, y)&lt;/code&gt; are provided. To solve this issue, &lt;code&gt;ggplot2&lt;/code&gt; version 2.2.0 introduced &lt;code&gt;geom_col(aes(x, y))&lt;/code&gt; to take care bar plot from two variables. With &lt;code&gt;stat_count()&lt;/code&gt; and &lt;code&gt;geom_col()&lt;/code&gt;, &lt;code&gt;geom_bar()&lt;/code&gt; are ready to retire.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-organize-axis-and-legend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to organize axis and legend&lt;/h2&gt;
&lt;p&gt;Almost all components regarding axis and legend can be specified in &lt;code&gt;scale_xxx_xxx()&lt;/code&gt; funtions. You can get the job done by only using them. The code may be too busy though. Several help functions do part of &lt;code&gt;scale_xxx_xxx()&lt;/code&gt;’s job and make the code succint, such as &lt;code&gt;xlab()&lt;/code&gt; and &lt;code&gt;ylim()&lt;/code&gt;. But too many help functions also make code less structured.&lt;/p&gt;
&lt;p&gt;I like two help functions: &lt;code&gt;labs()&lt;/code&gt; sets titles of all axis and lengends and &lt;code&gt;guides()&lt;/code&gt; arranges multiple legends. Together with &lt;code&gt;scale_xxx_xxx()&lt;/code&gt;, the three take care axis and legend in a logical way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;scale_xxx_xxx()&lt;/code&gt; determines what to show. They are used to set limits, breaks and labels of each aesthetics, which are the real data to show.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;guides()&lt;/code&gt; determines how to display. It is a best practice to arrange each legend by considering all others the same time.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;labs()&lt;/code&gt; determines how to call them. It names axis and legend in one place by treating all axis and legend as a whole, which helps to name them in the same style.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(hwy, cty, color = factor(cyl), shape = drv)) +
    geom_point(aes(size = displ)) +
    # what to display
    scale_x_continuous(limits = c(0, 50),
                       breaks = c(0, 20, 40),
                       labels = c(&amp;quot;zero&amp;quot;, &amp;quot;twenty&amp;quot;, &amp;quot;fourty&amp;quot;), 
                       minor_breaks = c(5, 10, 15)) +
    scale_color_discrete(breaks = c(4, 5, 6, 8), 
                         labels = c(&amp;quot;four&amp;quot;, &amp;quot;five&amp;quot;, &amp;quot;six&amp;quot;, &amp;quot;eight&amp;quot;)) + # asign colors by default
                                    
    scale_shape_manual(limits = c(&amp;quot;f&amp;quot;, &amp;quot;r&amp;quot;),      # manually select shape
                       values = c(f = 0, r = 2)) +
    # how to display
    guides(
        size = &amp;quot;none&amp;quot;,  # hide size
        color = guide_legend(direction = &amp;quot;horizontal&amp;quot;,
                             title.position = &amp;quot;top&amp;quot;,
                             nrow = 2,
                             byrow = TRUE,  # arrange row by row, default is by column
                             order = 1),    # first legend to show
        shape = guide_legend(direction = &amp;quot;vertical&amp;quot;,
                             reverse = TRUE)  # reverse order of legend keys
    ) +
    # what&amp;#39;s your name
    labs(title = &amp;quot;Use scale_xxx(), guides(), and labs() for legend and axis&amp;quot;,
         subtitle = &amp;quot;scale_xxx for what to display, guides for how to display, labs for how to name&amp;quot;,
         x = &amp;quot;highway mileage&amp;quot;,
         y = &amp;quot;city mileage&amp;quot;, 
         color = &amp;quot;cylinder&amp;quot;, 
         shape = &amp;quot;drive train&amp;quot;, 
         size = &amp;quot;haha you cannot see me&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-03-a-uniform-way-to-use-ggplot2_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-do-a-quick-annotation-with-annotate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s do a quick annotation with &lt;code&gt;annotate()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Annotation with &lt;code&gt;annotate()&lt;/code&gt; is handy when you simply want to draw something using vectors. It can draw &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;segment&lt;/code&gt;, &lt;code&gt;rect&lt;/code&gt;, and pretty much everything &lt;code&gt;geom_xxx()&lt;/code&gt; offers. Do not get confused with &lt;code&gt;geom_text()&lt;/code&gt; and &lt;code&gt;geom_segment()&lt;/code&gt;, and &lt;code&gt;geom_rect&lt;/code&gt;, …, which use dataframes. Reserve &lt;code&gt;annotate()&lt;/code&gt; for drawing simple things manually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(displ, hwy, color = drv)) +
    geom_point() +
    annotate(&amp;quot;text&amp;quot;, x = 6, y = 35, label = &amp;quot;These big guys\nare gas efficient.&amp;quot;) +
    annotate(&amp;quot;segment&amp;quot;, x = c(5.8, 6, 6.2), y = 32.5, 
             xend = c(5.7, 6.15, 6.9), yend = c(27, 27, 25.1),
             arrow = arrow(angle = 20, length = unit(2, &amp;quot;mm&amp;quot;), type = &amp;quot;closed&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-03-a-uniform-way-to-use-ggplot2_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finally-a-comprehensive-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finally a comprehensive example&lt;/h2&gt;
&lt;p&gt;In addition to the confusing parts discussed above, a normal &lt;code&gt;ggplot2&lt;/code&gt; plot may contains &lt;code&gt;position&lt;/code&gt;, &lt;code&gt;facet&lt;/code&gt;, and of course &lt;code&gt;theme()&lt;/code&gt;. I will conclude this post with an example that covers all major components of a &lt;code&gt;ggplot2&lt;/code&gt; plot. This is the uniform way I am using &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mpg, aes(factor(cyl), cty)) +
    # leave color and size in geom_point() so that stat_boxplot works on all data
    geom_point(aes(color = drv, size = displ), position = &amp;quot;jitter&amp;quot;) +
    stat_boxplot(fill = NA) + 
    facet_wrap(~year) +

    # === take care axis and legend ===
    
    # determine what values and labels to display
    scale_x_discrete(breaks = c(4, 5, 6, 8),
                     labels = c(&amp;quot;Four&amp;quot;, &amp;quot;Five&amp;quot;, &amp;quot;Six&amp;quot;, &amp;quot;Eight&amp;quot;)) +
    scale_y_continuous(limits = c(4, 36),
                       breaks = 1:4 * 8) +
    scale_color_manual(breaks = c(&amp;quot;4&amp;quot;, &amp;quot;f&amp;quot;, &amp;quot;r&amp;quot;),
                       values = c(&amp;quot;4&amp;quot; = &amp;quot;red&amp;quot;, &amp;quot;f&amp;quot; = &amp;quot;blue&amp;quot;, &amp;quot;r&amp;quot; = &amp;quot;cyan&amp;quot;),
                       labels = c(&amp;quot;four-wheel&amp;quot;, &amp;quot;front-wheel&amp;quot;, &amp;quot;rear-wheel&amp;quot;)) +
    scale_size_area(limits = c(2, 7),
                          max_size = 4) +
    
    # make arrangement for each legend
    guides(
        size = guide_legend(
            title.position = &amp;quot;top&amp;quot;,
            nrow = 2,
            byrow = TRUE,
            override.aes = list(shape = 1),
            reverse = TRUE
        ),
        color = guide_legend(
            order = 1,
            nrow = 3,
            override.aes = list(size = 3)
        )
    ) +
    
    # using labs() for all of the titles and labels in one place
    labs(title = &amp;quot;This plot displays all major ggplot components&amp;quot;,
         subtitle = &amp;quot;including data, aes mapping, geom, stat, position, facet, scale, guides, annotaion, and theme&amp;quot;,
         caption = &amp;quot;Source: what so ever&amp;quot;,
         x = &amp;quot;Cylinders&amp;quot;,
         y = &amp;quot;City Mileage (miles/gallon)&amp;quot;,
         color = NULL,
         size = &amp;quot;displacement&amp;quot;) +
    
    # === provide extra information ===
    
    # annotate extra geoms mannually. Play with geom_text() if want to label in
    # a specific facet panel
    annotate(&amp;quot;text&amp;quot;, x = 0.5, y = 6, label = &amp;quot;boxplot is applied to all data&amp;quot;, 
             hjust = 0, vjust = 1) +
    
    # === use theme() to make it beautiful ===
    
    theme(plot.background = element_rect(fill = &amp;quot;#F5E6E3&amp;quot;),
          plot.title = element_text(family = &amp;quot;monospace&amp;quot;),
          plot.subtitle = element_text(face = &amp;quot;italic&amp;quot;),
          panel.background = element_rect(fill = &amp;quot;lightblue&amp;quot;, color = &amp;quot;red&amp;quot;),
          panel.grid.major.y = element_line(color = &amp;quot;grey95&amp;quot;, size = 0.2),
          panel.grid.minor.y = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_text(family = &amp;quot;monospace&amp;quot;),
          legend.position = &amp;quot;top&amp;quot;,
          legend.key = element_blank(),
          legend.margin = margin(0, 0, 0, 0),
          legend.background = element_blank(),
          strip.background = element_blank(),
          strip.text = element_text(size = 12))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./post/2017-08-03-a-uniform-way-to-use-ggplot2_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Compare data.table pipes and magrittr pipes</title>
      <link>/2017/07/25/compare-data.table-pipes-and-magrittr-pipes/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/25/compare-data.table-pipes-and-magrittr-pipes/</guid>
      <description>&lt;p&gt;We have two ways to chain &lt;code&gt;data.table&lt;/code&gt; operations, using &lt;code&gt;data.table&lt;/code&gt; pipes or using &lt;code&gt;magrittr&lt;/code&gt; pipes. For a data.table &lt;code&gt;dt&lt;/code&gt;, the &lt;code&gt;data.table&lt;/code&gt; pipes take the form of &lt;code&gt;dt[][][]...&lt;/code&gt; and &lt;code&gt;magrittr&lt;/code&gt; pipes &lt;code&gt;dt %&amp;gt;% .[] %&amp;gt;% .[] %&amp;gt;% ...&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s first compare the readability of the two pipes in the following examples. Hadley Wickham criticized the readability of &lt;code&gt;data.table&lt;/code&gt; pipes in this &lt;a href=&#34;https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly&#34;&gt;stackoverflow post&lt;/a&gt;. The &lt;code&gt;data.table&lt;/code&gt; pipes, however, are not that hard to follow for those who are familiar with &lt;code&gt;data.table&lt;/code&gt;. To my eyes, the &lt;code&gt;magrittr&lt;/code&gt; pipes improve the readability but the &lt;code&gt;data.table&lt;/code&gt; pipes are still acceptable. It is more of a personal choice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(magrittr)

# the data.table pipes
data.table(iris)[
    # add a new column &amp;quot;is_setosa&amp;quot;, 1 if yes and 0 if no, use two lines of codes 
    # to clearly show the values
    Species == &amp;quot;setosa&amp;quot;, is_setosa := 1
][
    Species != &amp;quot;setosa&amp;quot;, is_setosa := 0
][
    # changes the Petal.Length of Species &amp;quot;versicolor&amp;quot;, other species not affected
    Species == &amp;quot;versicolor&amp;quot;, Petal.Length := 999
][
    # calculate sepal area when length &amp;gt; 5. Area is NA if length &amp;lt;= 5
    Sepal.Length &amp;gt; 5, Sepal.Area := Sepal.Length * Sepal.Width
][
    # select columns
    , .(Species, is_setosa, Petal.Length, Sepal.Area)
][
    # average of each column grouped by species
    , lapply(.SD, mean, na.rm = TRUE), by = Species
]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Species is_setosa Petal.Length Sepal.Area
## 1:     setosa         1        1.462   19.76364
## 2: versicolor         0      999.000   16.87340
## 3:  virginica         0        5.552   19.83633&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the magrittr pipes
data.table(iris) %&amp;gt;%
    # add a new column &amp;quot;is_setosa&amp;quot;, 1 if yes and 0 if no, use two lines of codes 
    # to clearly show the values
    .[Species == &amp;quot;setosa&amp;quot;, is_setosa := 1] %&amp;gt;%                         
    .[Species != &amp;quot;setosa&amp;quot;, is_setosa := 0] %&amp;gt;%
    
    # changes the Petal.Length of Species &amp;quot;versicolor&amp;quot;, other species not affected
    .[Species == &amp;quot;versicolor&amp;quot;, Petal.Length := 999] %&amp;gt;%   
    
    # calculate sepal area when length &amp;gt; 5. Area is NA if length &amp;lt;= 5
    .[Sepal.Length &amp;gt; 5, Sepal.Area := Sepal.Length * Sepal.Width] %&amp;gt;%  
    
    # select columns
    .[, .(Species, is_setosa, Petal.Length, Sepal.Area)] %&amp;gt;%    
    
    # average of each column grouped by species
    .[, lapply(.SD, mean, na.rm = TRUE), by = Species]                  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Species is_setosa Petal.Length Sepal.Area
## 1:     setosa         1        1.462   19.76364
## 2: versicolor         0      999.000   16.87340
## 3:  virginica         0        5.552   19.83633&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Will the use of pipes &lt;code&gt;%&amp;gt;%&lt;/code&gt; slow down the computing? In the following code, we add three new columns to a made-up data table with &lt;code&gt;data.table&lt;/code&gt; pipes and &lt;code&gt;magrittr&lt;/code&gt; pipes. They almost have the same speed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
dt &amp;lt;- data.table(a = sample(letters, 1e5, replace = TRUE),
                 b = abs(rnorm(1e5)))

datatable_pipe &amp;lt;- function(){
    dt[, x := sqrt(b)][
        , y := b^2
    ][
        , z := paste0(a , b)
    ]
}

magrittr_pipe &amp;lt;- function(){
    dt[, x := sqrt(b)] %&amp;gt;%
        .[, y := b^2] %&amp;gt;%
        .[, z := paste0(a , b)]
}

rbenchmark::benchmark(datatable_pipe(), magrittr_pipe(), replications=20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               test replications elapsed relative user.self sys.self
## 1 datatable_pipe()           20   3.765    1.062     3.752    0.012
## 2  magrittr_pipe()           20   3.545    1.000     3.539    0.004
##   user.child sys.child
## 1          0         0
## 2          0         0&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>&lt;p&gt;This is GL Li&amp;rsquo;s personal website. I love to dig into census data with R to find interesting numbers and apply the data to political, social, and economic problems. A main focus of this site is to discuss how to process census data with R, in particular, using the &lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34;&gt;totalcensus package&lt;/a&gt; I am developing. As a lifelong learner, I also like to share skills and tricks I have learned about R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/collections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/collections/</guid>
      <description>

&lt;h1 id=&#34;a-collection-of-interesting-online-articles&#34;&gt;A collection of Interesting online articles&lt;/h1&gt;

&lt;h3 id=&#34;building-dot-density-maps-with-uk-census-data-in-r-https-www-blog-cultureofinsight-com-2017-06-building-dot-density-maps-with-uk-census-data-in-r&#34;&gt;&lt;a href=&#34;https://www.blog.cultureofinsight.com/2017/06/building-dot-density-maps-with-uk-census-data-in-r/&#34;&gt;Building Dot Density Maps with UK Census Data in R&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;scatterpie-for-plotting-pies-on-ggplot-https-guangchuangyu-github-io-2016-12-scatterpie-for-plotting-pies-on-ggplot&#34;&gt;&lt;a href=&#34;https://guangchuangyu.github.io/2016/12/scatterpie-for-plotting-pies-on-ggplot/&#34;&gt;scatterpie for plotting pies on ggplot&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;8-useful-shell-commands-for-data-science-https-www-datacamp-com-community-tutorials-shell-commands-data-scientist&#34;&gt;&lt;a href=&#34;https://www.datacamp.com/community/tutorials/shell-commands-data-scientist&#34;&gt;8 Useful Shell Commands For Data Science&lt;/a&gt;&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/links/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/links/</guid>
      <description>

&lt;h1 id=&#34;list-of-r-and-census-blogs&#34;&gt;List of R and census blogs&lt;/h1&gt;

&lt;h3 id=&#34;r-bloggers-https-www-r-bloggers-com&#34;&gt;&lt;a href=&#34;https://www.r-bloggers.com/&#34;&gt;R-Bloggers&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;R news and tutorials contributed by (750) R bloggers&lt;/p&gt;

&lt;h3 id=&#34;census-bureau-s-blogs-https-www-census-gov-newsroom-blogs-about-html&#34;&gt;&lt;a href=&#34;https://www.census.gov/newsroom/blogs/about.html&#34;&gt;Census Bureau&amp;rsquo;s Blogs&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Including &lt;a href=&#34;https://www.census.gov/newsroom/blogs/director.html&#34;&gt;Director&amp;rsquo;s Blog&lt;/a&gt;, &lt;a href=&#34;https://www.census.gov/newsroom/blogs/random-samplings.html&#34;&gt;Random Sampling&lt;/a&gt;, &lt;a href=&#34;https://www.census.gov/newsroom/blogs/research-matters.html&#34;&gt;Research Matters&lt;/a&gt;, and &lt;a href=&#34;https://www.census.gov/newsroom/blogs/global-reach.html&#34;&gt;Global Reach&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-census-project-blog-https-thecensusproject-org-blog&#34;&gt;&lt;a href=&#34;https://thecensusproject.org/blog/&#34;&gt;The Census Project Blog&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Commentary on Census and ACS policy and operational issues.&lt;/p&gt;

&lt;h3 id=&#34;kyle-walker-data-https-walkerke-github-io&#34;&gt;&lt;a href=&#34;https://walkerke.github.io/&#34;&gt;Kyle Walker Data&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Blog of the author of &lt;code&gt;tidycensus&lt;/code&gt; and &lt;code&gt;tigris&lt;/code&gt; packages.&lt;/p&gt;

&lt;h3 id=&#34;yihui-s-blog-https-yihui-name-en&#34;&gt;&lt;a href=&#34;https://yihui.name/en/&#34;&gt;Yihui&amp;rsquo;s blog&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Blog of the author of popular packages such as &lt;code&gt;knitr&lt;/code&gt; and &lt;code&gt;blogdown&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description>

&lt;h1 id=&#34;totalcensus-package-extract-census-data-from-summary-files-https-github-com-gl-li-totalcensus&#34;&gt;&lt;a href=&#34;https://github.com/GL-Li/totalcensus&#34;&gt;totalcensus package: extract census data from summary files&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;The totalcensus package extracts any data available in the raw summary files of decennial census and American Community Survey (ACS) and returns a tidy &lt;code&gt;data.table&lt;/code&gt; that can be easily processed with &lt;code&gt;data.table&lt;/code&gt; or &lt;code&gt;dplyr&lt;/code&gt; packages.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;fatal-police-shooting-in-the-united-states&#34;&gt;Fatal police shooting in the United States&lt;/h1&gt;

&lt;h3 id=&#34;black-people-are-more-likely-to-be-killed-by-police-in-blue-states-than-in-red-states-https-github-com-gl-li-police-shooting&#34;&gt;&lt;a href=&#34;https://github.com/GL-Li/police_shooting&#34;&gt;Black people are more likely to be killed by police in blue states than in red states&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;In large urban areas, black people are 1.96 time as likely to be fatally shot by police as non-black people in red states while it is 3.00 times in blue states. For those unarmed victims, the disparity is 3.02 in red states and as high as 4.66 in blue states.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;china-census-2010-http-useshiny-com-apps-china-census&#34;&gt;&lt;a href=&#34;http://useshiny.com/apps/China_census/&#34;&gt;China census 2010&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;This &lt;code&gt;Shiny&lt;/code&gt; application visualizes the China 2010 census. China has conducted a national census of all population every ten years since 1990, collecting data such as age, gender, education and housing. The most recent one was carried out in November 01, 2010. The official summary of the census is published on the webpage of &lt;a href=&#34;http://www.stats.gov.cn/tjsj/pcsj/rkpc/6rp/indexch.htm&#34;&gt;National Bureau of Statistics of China&lt;/a&gt; as Excel sheets. This app attempts to convey the information essential to understanding China through interactive visualization.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;predict-next-words-https-gl-li-shinyapps-io-nextword-shinyapp&#34;&gt;&lt;a href=&#34;https://gl-li.shinyapps.io/nextWord_ShinyApp/&#34;&gt;Predict next words&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;This is the 2015 capstone project of &lt;a href=&#34;https://www.coursera.org/specializations/jhu-data-science&#34;&gt;Data Science Specialization&lt;/a&gt; offered by Johns Hopkins University. In this project we build a web application to predict the next words following each key press. This kind of applications have been widely used for text input in mobile devices such as cell phones and tablets.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>