---
title: Improve data.table readability with pipes
author: GL
date: '2017-07-25'
slug: improve-data-table-readability-with-pipes
categories:
  - data.table
tags:
  - data wrangling
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Package ```data.table```  is sometimes criticized for its poorer readability than its competitor ```dplyr```. As a data.table user, I had the same feeling at the early days of using it. I love the concise syntax, which takes care a lot of tasks simply with ```dt[i, j, by]```. You can put many codes at the ``j`` section. You can even chain ``[i, j, by]`` together and make  train-like code ```dt[...][...]...```. In a [stackoverflow thread](http://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly), Hadley Wickman, the creator of ```dplyr```, criticizes the poor readability of ```data.table``` caused by the train through the follow example. This train only has two cars but is alread hard to read.
```{r}
library(magrittr)
library(data.table)
library(ggplot2)
diamondsDT <- data.table(diamonds)

# this is the train with two cars
diamondsDT[
  cut != "Fair", 
  .(AvgPrice = mean(price),
    MedianPrice = as.numeric(median(price)),
    Count = .N
  ), 
  by = cut
][ 
  order(-Count) 
]
```

Pipes ```%>%``` in the ```magrittr``` package can improve the readability. It explicitly break the train apart. Each new car then starts a new line with a confortable indentation. It helps more when the train has more cars.
```{r}
diamondsDT[cut != "Fair", 
           .(AvgPrice = mean(price),
             MedianPrice = as.numeric(median(price)),
             Count = .N), 
           by = cut] %>% 
    .[order(-Count)]    # this car starts with a conforable indentation
```


The pipe ```%>%``` is particularly useful when adding or updating columns. Here is a dummy example. It does not make scientific sense but demonstrates how readable the code can be. The use of pipe ```%>%``` makes the code look like ```dplyr``` code but is more powerful. Each car focuses on one job and each job focuses on a columnb with selected rows. The selected rows can be independent from other cars. This is a big advantage over ```dplyr``` where ```filter()``` affects all codes that follow. 
```{r}
avg <- data.table(iris) %>%
    # add a new column "is_setosa", 1 if yes and 0 if no, use two lines of codes 
    # to clearly show the values
    .[Species == "setosa", is_setosa := 1] %>%                         
    .[Species != "setosa", is_setosa := 0] %>%
    # changes the Petal.Length of Species "versicolor", other species not affected
    .[Species == "versicolor", Petal.Length := 999] %>%   
    # calculate sepal area when length > 5. Area is NA if length <= 5
    .[Sepal.Length > 5, Sepal.Area := Sepal.Length * Sepal.Width] %>%  
    # select columns
    .[, .(Species, is_setosa, Petal.Length, Sepal.Area)] %>%    
    # average of columns grouped by species
    .[, lapply(.SD, mean, na.rm = TRUE), by = Species] %>%  
    # display result
    print()                                                            
```

How about speed?  ```data.table``` is built for its fast speed. Will the use of pipes ```%>%``` slow down the computing? Usually we do not care when data is not that big. But what if we care? In the following example, we add three new columns to a made-up data table with and without using the pipes. The pipes actually makes the computing faster in this example. 

```{r}
# elapsed time of adding three columns in a data table with one dt[]
set.seed(123)
dt <- data.table(a = 1:1e7,
                 b = rnorm(1e7))

no_pipe <- function(){
    dt[, ":=" (x = sqrt(a), y = b^2, z = a * b)]
}

with_pipe <- function(){
        dt[, x := sqrt(a)] %>%
            .[, y := b^2] %>%
            .[, z := a * b]
}

rbenchmark::benchmark(s1 <- no_pipe(), s2 <- with_pipe(), order="elapsed", replications=10)
```
